### List != 배열
* 배열: 공간(메모리)상에서 볼때 연속적
* list: 공간(메모리)상에서 볼때 불연속적


### 신경망기초
* binary classification: 2진분류 -> 직선 1개로 참, 거짓을 나눌 수 있음

* 확장슬라이싱 a[::2] -> [0,2,4,6,8...]
* 역인덱싱: a[-1] -> 뒤부터 접근 (-1: 가장 뒤 원소)


* ex(len(a)==100): a[0:50] == a[0:-50]

* 리스트내장: i_1=['frame_' + str(i) for i in range(0,100)]
* 2중 내장: i_1=[str(i)+str(j) for i in range(0,100) for j in range(5)]

* in : 배열에서 원소 존재 확인 -> 100 in i -> i에 100이 있는지 확인

* [].sort() : default는 오름차순 정렬

* os.walk

* 파일경로 지정 \대신 / 사용 권장 -> os 모듈에서 변경시켜 사용

* 벡터는 '함수'(정의역, 치역이 같은 공간이면 벡터!)

* 파이썬 메소드의 첫 매개변수가 self인 이유 -> 절차형 언어에서 객체지향을 도입하기 위해

* np.where : 조건설정 (SQL에서의 WHERE 역할)

## 08/23
* 대수론적 관점 -> 계산보다는 형태에 집중 (ex: 식의 전개)

* cs231n -> AI korea에서 한글화 중

* one-hot-encoding (=0,1 encoding) -> 0, 1만 존재함을 이용해 if문 생략하는 것도 가능

* classification - regression -> 분류: 꼭 특정 선 위에 없어도 됨(나눌수 있으면 됨) , 회귀: 최대한 많은 값을 포함하는 직선을 찾는 것

 * log를 사용하는 이유: 오차역전파법(미분)시용시, 어디서 시작해도 최소값에 도달할 수 있음을 보장 할 수 있음

* 피클을 사용하지 않고, numpy, tessorflow가 가지고 있는 파일저장 기능을 이용해 저장하는 것이 여러가지 면에서 바람직(단, tf의 파일저장 기능은 기존의 파일을 덮어쓰는것이 아니라 파일이 저장할때 마다 새로 생성되는 문제점 있음)

* Multinomaial classification은 binary classification을 통해 구현할 수 있음(이진 분류 여러개)

* sigmoid는 절대적(함수의 결과 값) softmax는 상대적(확률)

* 엔트로피 개념 적용을 위해 원핫인코딩 사용

* 역전파(back propagation)은 함성함수 미분과 동일 -> 함수간의 관계는 종속적이나, 수치미분의 관점에서 볼때 그래프의 기울기 만을 전달 -> 값은 독립적

* tf의 Variable: 텐서(tensor)라고 부름

## 번외 - 논문참조
* arxiv.org
* ICML
* NIPS -> practice and trends

* practice and trends: 학술대회, PPT
* tutorial: 분야 전체의 역사, 앞으로의 진행 방향등 제시

* 제목으로 트랜드파악 0> abstract 읽기 -> conclusion(결론) -> introduction
* 서론: 풀려고하는 문제, 분야 (review논문은 introduction을 확장)
* 본문 and 실험(method and experience): 

* 수식은 블랙박스 관점에서 접근해도됨(물론 알면 좋음) <br>핵심스토리에 집중</br>
* 나는 저자가 아님! -> 필요한 부분만 읽는다!

* 정해진 형식을 지키는 책(논문)이 좋은책(논문)!

* 대학원생때 알았으면 좋았을 이야기

* 구글스칼라: 